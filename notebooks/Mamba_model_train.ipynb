{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T19:40:55.425947Z",
     "start_time": "2024-03-21T19:40:53.014499Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filif/miniconda3/envs/pixgan/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from mamba_ssm.models.mixer_seq_simple import MambaConfig, MambaLMHeadModel\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import torch.nn.functional as F\n",
    "from miditok import REMI, TokenizerConfig\n",
    "from miditok.pytorch_data import DatasetTok, DataCollator\n",
    "from pathlib import Path\n",
    "from symusic import Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T19:40:55.429743Z",
     "start_time": "2024-03-21T19:40:55.427125Z"
    }
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T19:49:30.554065Z",
     "start_time": "2024-03-21T19:41:20.515228Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: ../data/maestro-v3.0.0/2018: 100%|██████████| 93/93 [00:20<00:00,  4.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Creating a multitrack tokenizer configuration, read the doc to explore other parameters\n",
    "config = TokenizerConfig(num_velocities=16, use_chords=True, use_programs=True)\n",
    "tokenizer = REMI(config)\n",
    "# tokenizer = REMI(params='./tokenizer.json')\n",
    "\n",
    "# Trains the tokenizer with BPE, and save it to load it back later\n",
    "midi_paths = list(Path(\"../data/maestro-v3.0.0/2018\").glob(\"**/*.midi\"))\n",
    "# tokenizer.learn_bpe(vocab_size=VOCAB_SIZE, files_paths=midi_paths)\n",
    "# tokenizer.save_params(Path(\"tokenizer.json\"))\n",
    "\n",
    "# Creates a Dataset and a collator to be used with a PyTorch DataLoader to train a model\n",
    "dataset = DatasetTok(\n",
    "    files_paths=midi_paths,\n",
    "    min_seq_len=100,\n",
    "    max_seq_len=1024,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "collator = DataCollator(\n",
    "    tokenizer[\"PAD_None\"], tokenizer[\"BOS_None\"], tokenizer[\"EOS_None\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T20:07:12.773309Z",
     "start_time": "2024-03-21T20:07:12.769822Z"
    }
   },
   "outputs": [],
   "source": [
    "config = MambaConfig(d_model=384,\n",
    "                     n_layer=2,\n",
    "                     vocab_size=VOCAB_SIZE)\n",
    "\n",
    "class MambaModel(nn.Module):\n",
    "    def __init__(self, config) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = MambaLMHeadModel(self.config).to('cuda')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x).logits\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T20:07:13.907218Z",
     "start_time": "2024-03-21T20:07:12.920834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaModel(\n",
       "  (model): MambaLMHeadModel(\n",
       "    (backbone): MixerModel(\n",
       "      (embedding): Embedding(5000, 384)\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Block(\n",
       "          (mixer): Mamba(\n",
       "            (in_proj): Linear(in_features=384, out_features=1536, bias=False)\n",
       "            (conv1d): Conv1d(768, 768, kernel_size=(4,), stride=(1,), padding=(3,), groups=768)\n",
       "            (act): SiLU()\n",
       "            (x_proj): Linear(in_features=768, out_features=56, bias=False)\n",
       "            (dt_proj): Linear(in_features=24, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=384, bias=False)\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm_f): RMSNorm()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=384, out_features=5000, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 3e-4\n",
    "mamba = MambaModel(config)\n",
    "\n",
    "mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T20:14:55.570450Z",
     "start_time": "2024-03-21T20:14:55.566598Z"
    }
   },
   "outputs": [],
   "source": [
    "class LitMamba(L.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch = batch['input_ids']\n",
    "        x, y_true = batch[:, :-1], batch[:, 1:]\n",
    "        \n",
    "        y_pred = self.model(x) # -> BATCH x SEQ x VOCAB\n",
    "        \n",
    "        y_pred = y_pred.reshape(-1, y_pred.shape[-1])\n",
    "        y_true = y_true.reshape(-1)\n",
    "\n",
    "        loss = F.cross_entropy(y_pred, y_true)\n",
    "        \n",
    "        # TODO\n",
    "        self.logger.experiment.add_scalar('Loss', loss, self.trainer.global_step)\n",
    "        # self.logger.experiment\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(mamba.parameters(), lr=3e-4)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T20:14:55.718697Z",
     "start_time": "2024-03-21T20:14:55.716282Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset=dataset, collate_fn=collator, batch_size=4, num_workers=11)\n",
    "\n",
    "m = LitMamba(mamba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T20:17:06.107643Z",
     "start_time": "2024-03-21T20:14:56.365296Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")\n",
    "trainer = L.Trainer(max_epochs=5, devices=1, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | MambaModel | 3.8 M \n",
      "-------------------------------------\n",
      "3.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.8 M     Total params\n",
      "15.395    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1001/1001 [00:30<00:00, 33.36it/s, v_num=6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1001/1001 [00:30<00:00, 33.21it/s, v_num=6]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=m, train_dataloaders=data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mamba_ssm.utils.generation import decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_loader:\n",
    "    sample = i['input_ids'][1:2, :80]\n",
    "    break\n",
    "\n",
    "\n",
    "test_music = decode(sample.to('cuda'), model=mamba.model.to('cuda'), max_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1, 102, 124, 281,  37, 100, 129, 188, 281,  30, 100, 111, 194, 281,\n",
       "          46,  99, 116, 281,  54, 103, 117, 201, 281,  40, 100, 111,   4, 187,\n",
       "         281,  36,  97, 126, 190, 281,  45,  98, 115, 281,  54,  98, 140, 195,\n",
       "         281,  28,  97, 110, 200, 281,  47, 100, 118, 201, 281,  45,  98, 113,\n",
       "           4, 173, 281,  40,  98, 112, 176, 281,  48, 101, 125, 281,  52,  99,\n",
       "         119, 177, 281,  36,  98, 120, 181, 281,  28,  96, 112, 185, 281,  40,\n",
       "          98, 110, 189, 281,  40,  98, 110, 192, 281,  40,  98, 110, 195, 281,\n",
       "          40,  98, 110, 197, 281,  40,  98, 110, 199, 281,  40,  98, 110, 201,\n",
       "         281,  40,  98, 110, 204, 281,  40,  98, 110,   4, 175, 281,  40,  98,\n",
       "         110, 177, 281,  40,  98, 110, 179, 281,  40,  98, 110, 181, 281,  40,\n",
       "          98, 110, 183, 281,  40,  98, 110, 185, 281,  40,  98, 110, 187, 281,\n",
       "          40,  98, 110, 189, 281,  40,  98, 110, 191, 281,  40,  98, 110, 193,\n",
       "         281,  40,  98, 110, 195, 281,  40,  98, 110, 197, 281,  40,  98, 110,\n",
       "         199, 281,  40,  98, 110, 201, 281,  40,  98, 110, 203, 281,  40,  98,\n",
       "         110,   4, 173, 281,  40,  98, 110, 175, 281,  40,  98, 110, 177, 281,\n",
       "          40,  98, 110, 179, 281,  40,  98, 110, 181, 281,  40,  98, 110, 183,\n",
       "         281,  40,  98, 110, 185, 281,  40,  98, 110, 187, 281,  40,  98, 110,\n",
       "         189, 281,  40,  98, 110, 191, 281,  40,  98, 110, 193, 281,  40,  98,\n",
       "         110, 195, 281,  40,  98, 110, 197, 281,  40,  98, 110, 199, 281,  40,\n",
       "          98, 110, 201, 281,  40,  98, 110, 203, 281,  40,  98, 110,   4, 173,\n",
       "         281,  40,  98, 110, 175, 281,  40,  98, 110, 177, 281,  40,  98, 110,\n",
       "         179, 281,  40,  98, 110, 181, 281,  40,  98, 110, 183, 281,  40,  98,\n",
       "         110, 185, 281,  40,  98, 110, 187, 281,  40,  98, 110, 189, 281,  40,\n",
       "          98, 110, 191, 281,  40,  98, 110, 193, 281,  40,  98, 110, 195, 281,\n",
       "          40,  98, 110, 197, 281,  40,  98, 110, 199, 281,  40,  98, 110, 201,\n",
       "         281,  40,  98, 110, 203, 281,  40,  98, 110,   4, 173, 281,  40,  98,\n",
       "         110, 175, 281,  40,  98, 110, 177, 281,  40,  98, 110, 179, 281,  40,\n",
       "          98, 110, 181, 281,  40,  98, 110, 183, 281,  40,  98, 110, 185, 281,\n",
       "          40,  98, 110, 187, 281,  40,  98, 110, 189, 281,  40,  98, 110, 191,\n",
       "         281,  40,  98, 110, 193, 281,  40,  98, 110, 195, 281,  40,  98, 110,\n",
       "         197, 281,  40,  98, 110, 199, 281,  40,  98, 110, 201, 281,  40,  98,\n",
       "         110, 203, 281,  40,  98, 110,   4, 173, 281,  40,  98, 110, 175, 281,\n",
       "          40,  97, 110, 177, 281,  40,  97, 110, 179, 281,  40,  97, 110, 181,\n",
       "         281,  40,  97, 110, 183, 281,  40,  97, 110, 185, 281,  40,  97, 110,\n",
       "         187, 281,  40,  97, 110, 189, 281,  40,  97, 110, 191, 281,  40,  97,\n",
       "         110, 193, 281,  40,  97, 110, 195, 281,  40,  97, 110, 197, 281,  40,\n",
       "          97, 110, 199, 281,  40,  97, 110, 201, 281,  40,  97, 110, 203, 281,\n",
       "          40,  97, 110,   4, 173, 281,  40,  97, 110, 175, 281,  40,  97, 110,\n",
       "         177, 281,  40,  97, 110, 179, 281,  40,  97, 110, 181, 281,  40,  97,\n",
       "         110, 183, 281,  40,  97, 110, 185, 281,  40,  97, 110, 187, 281,  40,\n",
       "          97, 110, 189, 281,  40,  97, 110, 191, 281,  40,  97, 110, 193, 281,\n",
       "          40,  97, 110, 195, 281,  40,  97, 110, 197, 281,  40,  97, 110, 199,\n",
       "         281,  40,  97, 110, 201, 281,  40,  97, 110, 203, 281,  40,  97, 110,\n",
       "           4, 173, 281,  40,  97, 110, 175, 281,  40,  97, 110, 177, 281,  40,\n",
       "          97, 110, 179, 281,  40,  97, 110, 181, 281,  40,  97, 110, 183, 281,\n",
       "          40,  97, 110, 185, 281,  40,  97, 110, 187, 281,  40,  97, 110, 189,\n",
       "         281,  40,  97, 110, 191, 281,  40,  97, 110, 193, 281,  40,  97, 110,\n",
       "         195, 281,  40,  97, 110, 197, 281,  40,  97, 110, 199, 281,  40,  97,\n",
       "         110, 201, 281,  40,  97, 110, 203, 281,  40,  97, 110,   4, 173, 281,\n",
       "          40,  97, 110, 175, 281,  40,  97, 110, 177, 281,  40,  97, 110, 179,\n",
       "         281,  40,  97, 110, 181, 281,  40,  97, 110, 183, 281,  40,  97, 110,\n",
       "         185, 281,  40,  97, 110, 187, 281,  40,  97, 110, 189, 281,  40,  97,\n",
       "         110, 191, 281,  40,  97, 110, 193, 281,  40,  97, 110, 195, 281,  40,\n",
       "          97, 110, 197, 281,  40,  97, 110, 199, 281,  40,  97, 110, 201, 281,\n",
       "          40,  97, 110, 203, 281,  40,  97, 110,   4, 173, 281,  40,  97, 110,\n",
       "         175, 281,  40,  97, 110, 177, 281,  40,  97, 110, 179, 281,  40,  97,\n",
       "         110, 181, 281,  40,  97, 110, 183, 281,  40,  97, 110, 185, 281,  40,\n",
       "          97, 110, 187, 281,  40,  97, 110, 189, 281,  40,  97, 110, 191, 281,\n",
       "          40,  97, 110, 193, 281,  40,  97, 110, 195, 281,  40,  97, 110, 197,\n",
       "         281,  40,  97, 110, 199, 281,  40,  97, 110, 201, 281,  40,  97, 110,\n",
       "         203, 281,  40,  97, 110,   4, 173, 281,  40,  97, 110, 175, 281,  40,\n",
       "          97, 110, 177, 281,  40,  97, 110, 179, 281,  40,  97, 110, 181, 281,\n",
       "          40,  97, 110, 183, 281,  40,  97, 110, 185, 281,  40,  97, 110, 187,\n",
       "         281,  40,  97, 110, 189, 281,  40,  97, 110, 191, 281,  40,  97, 110,\n",
       "         193, 281,  40,  97, 110, 195, 281,  40,  97, 110, 197, 281,  40,  97,\n",
       "         110, 199, 281,  40,  97, 110, 201, 281,  40,  97, 110, 203, 281,  40,\n",
       "          97, 110,   4, 173, 281,  40,  97, 110, 175, 281,  40,  97, 110, 177,\n",
       "         281,  40,  97, 110, 179, 281,  40,  97, 110, 181, 281,  40,  97, 110,\n",
       "         183, 281,  40,  97, 110, 185, 281,  40,  97, 110, 187, 281,  40,  97,\n",
       "         110, 189, 281,  40,  97, 110, 191, 281,  40,  97, 110, 193, 281,  40,\n",
       "          97, 110, 195, 281,  40,  97, 110, 197, 281,  40,  97, 110, 199, 281,\n",
       "          40,  97, 110, 201, 281,  40]], device='cuda:0')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_music.sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tokens_to_midi(test_music.sequences.reshape(-1).tolist()).dump_midi('xd.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixgan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
